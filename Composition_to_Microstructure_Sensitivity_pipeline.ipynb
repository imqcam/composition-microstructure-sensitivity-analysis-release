{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composition \u2192 Microstructure Sensitivity Pipeline\n\nThis notebook reproduces the original Python script in a Jupyter\u2011friendly, step\u2011by\u2011step format.\n\n* **Goal**: Predict \u03b3\u2032 phase fraction from alloy composition and analyse element sensitivities.\n* **Method**: Polynomial Chaos Expansion (PCE) surrogate model with Sobol sensitivity indices.\n* **Data**: An HDF5 file containing element mass fractions and measured phase fractions.\n\nFeel free to execute cells sequentially or modify parameters (e.g., file path, polynomial order range)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n#------------------------------------------------------------------------------#\n# 1. Imports & environment setup                                               #\n#------------------------------------------------------------------------------#\n\nimport h5py\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Surrogate modelling\nimport chaospy as cp\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Plotting defaults for notebook\n%matplotlib inline\nplt.rcParams.update({'font.size': 14, 'font.weight': 'bold'})\nsns.set_style('whitegrid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the dataset from HDF5\n\nChange `hdf5_path` if your data file has a different name or location. The file is expected to contain three datasets:\n\n* **`composition`** \u2014 2\u2011D array of mass fractions (Ni,\u202fCr,\u202fNb,\u202fMo,\u202fTi,\u202fAl,\u202fCo)\n* **`g_prime`** \u2014 \u03b3\u2032 phase fraction (float per alloy)\n* **`g_dprime`** \u2014 \u03b3\u2032\u2032 phase fraction (float per alloy)  \n\nThe loader converts these to NumPy arrays for further processing."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n#------------------------------------------------------------------------------#\n# 2. Data ingestion                                                            #\n#------------------------------------------------------------------------------#\n\nhdf5_path = \"Insert_your_file_name.hdf5\"   # <-- update if needed\n\nwith h5py.File(hdf5_path, 'r') as f:\n    composition_mass = np.array(f['composition'], dtype=np.float32)\n    g_prime = np.array(f['g_prime'], dtype=np.float32)\n    g_dprime = np.array(f['g_dprime'], dtype=np.float32)\n\nprint(\"Loaded:\", composition_mass.shape[0], \"alloys\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert mass fractions \u2192 mole fractions & build a DataFrame\n\nConversion uses atomic weights and assumes iron (Fe) is the balance element.  Values are expressed as *mole\u202f%*."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n#------------------------------------------------------------------------------#\n# 3. Mass-\u2192mole conversion                                                     #\n#------------------------------------------------------------------------------#\n\natomic_weights = {\n    'Fe': 55.845, 'Ni': 58.69, 'Cr': 52.00, 'Nb': 92.90,\n    'Mo': 95.95, 'Ti': 47.867, 'Al': 26.98154, 'Co': 58.933\n}\n\nNi, Cr, Nb, Mo, Ti, Al, Co = ([] for _ in range(7))\n\nfor row in composition_mass:\n    Fe_mass = 1.0 - row.sum()        # balancing Fe mass fraction\n    m_total = (\n        Fe_mass / atomic_weights['Fe']\n        + row[0] / atomic_weights['Ni']\n        + row[1] / atomic_weights['Cr']\n        + row[2] / atomic_weights['Nb']\n        + row[3] / atomic_weights['Mo']\n        + row[4] / atomic_weights['Ti']\n        + row[5] / atomic_weights['Al']\n        + row[6] / atomic_weights['Co']\n    )\n\n    Ni.append(row[0] / atomic_weights['Ni'] / m_total * 100)\n    Cr.append(row[1] / atomic_weights['Cr'] / m_total * 100)\n    Nb.append(row[2] / atomic_weights['Nb'] / m_total * 100)\n    Mo.append(row[3] / atomic_weights['Mo'] / m_total * 100)\n    Ti.append(row[4] / atomic_weights['Ti'] / m_total * 100)\n    Al.append(row[5] / atomic_weights['Al'] / m_total * 100)\n    Co.append(row[6] / atomic_weights['Co'] / m_total * 100)\n\ndf = pd.DataFrame({\n    \"Ni (mole %)\": Ni, \"Cr (mole %)\": Cr, \"Nb (mole %)\": Nb,\n    \"Al (mole %)\": Al, \"Ti (mole %)\": Ti, \"Co (mole %)\": Co,\n    \"Mo (mole %)\": Mo, \"\u03b3\u2032 (mole %)\": g_prime, \"\u03b3\u2032\u2032 (mole %)\": g_dprime\n})\n\ndf.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore variable distributions\n\nThe next cell plots histograms with KDE curves for each composition and phase\u2011fraction column."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n#------------------------------------------------------------------------------#\n# 4. Visualise distributions                                                   #\n#------------------------------------------------------------------------------#\n\nfig, axes = plt.subplots(nrows=3, ncols=3, figsize=(18, 14))\naxes = axes.flatten()\n\nfor ax, column in zip(axes, df.columns):\n    sns.histplot(df[column], kde=True, ax=ax)\n    ax.set_xlabel(column)\n    ax.set_ylabel(\"Count\")\n\nplt.tight_layout()\nplt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare inputs & target for PCE surrogate\n\n* **Features (X)**: first seven columns (element mole\u202f%).\n* **Target (y)**: \u03b3\u2032 mole\u202f%.\n\nUniform distributions are defined across the observed range of each feature and combined into an independent joint distribution."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n#------------------------------------------------------------------------------#\n# 5. Feature/target arrays + distributions                                     #\n#------------------------------------------------------------------------------#\n\nX = df.iloc[:, 0:7].values.astype('float64')\ny = df['\u03b3\u2032 (mole %)'].values.astype('float64')\n\ndists = [\n    cp.Uniform(df[col].min(), df[col].max())\n    for col in df.columns[:7]\n]\njoint_dist = cp.J(*dists)\n\n# Train/val/test split: 80/10/10\nX_train_val, X_test, y_train_val, y_test = train_test_split(\n    X, y, test_size=0.10, random_state=42\n)\nX_train, X_val, y_train, y_val = train_test_split(\n    X_train_val, y_train_val, test_size=0.1111, random_state=42\n)\nprint(\"Train:\", X_train.shape, \" Val:\", X_val.shape, \" Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hyper\u2011parameter search for polynomial order\n\nLoop over candidate orders (1\u202f\u2192\u202f4), fit a PCE on the training set, predict on the validation set, and store metrics."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n#------------------------------------------------------------------------------#\n# 6. Polynomial order sweep                                                    #\n#------------------------------------------------------------------------------#\n\norders = range(1, 5)\nval_mse, val_r2 = [], []\n\nfor order in orders:\n    poly = cp.expansion.stieltjes(order, joint_dist)\n    model = cp.fit_regression(poly, X_train.T, y_train)\n    y_pred = model(*X_val.T)\n    mse = mean_squared_error(y_val, y_pred)\n    r2 = r2_score(y_val, y_pred)\n    val_mse.append(mse)\n    val_r2.append(r2)\n    print(f\"Order {order}: val MSE={mse:.4f}, R\u00b2={r2:.4f}\")\n\nbest_order = orders[int(np.argmin(val_mse))]\nprint(\"\\nSelected polynomial order:\", best_order)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train final PCE & evaluate on hold\u2011out test set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n#------------------------------------------------------------------------------#\n# 7. Final model fit & test evaluation                                         #\n#------------------------------------------------------------------------------#\n\npoly_final = cp.expansion.stieltjes(best_order, joint_dist)\nmodel_final = cp.fit_regression(poly_final, X_train.T, y_train)\n\ny_test_pred = model_final(*X_test.T)\ntest_mse = mean_squared_error(y_test, y_test_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Test MSE={test_mse:.4f}, R\u00b2={test_r2:.4f}\")\n\n# KDE overlay\nplt.figure(figsize=(8,5))\nsns.kdeplot(y_test_pred, linewidth=3, label=\"Predicted \u03b3\u2032\")\nsns.kdeplot(y_test, linewidth=3, label=\"Actual \u03b3\u2032\")\nplt.xlabel(\"\u03b3\u2032 (mole %)\")\nplt.ylabel(\"Kernel density\")\nplt.legend()\nplt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Global sensitivity analysis (Sobol indices)\n\nChaospy can compute Sobol indices directly from the fitted PCE coefficients."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n#------------------------------------------------------------------------------#\n# 8. Sobol sensitivity indices                                                 #\n#------------------------------------------------------------------------------#\n\nmain_sobol = cp.Sens_m(model_final, joint_dist)\ntotal_sobol = cp.Sens_t(model_final, joint_dist)\n\nelements = ['Ni', 'Cr', 'Nb', 'Al', 'Ti', 'Co', 'Mo']\nsobol_df = pd.DataFrame({\n    'Element': elements,\n    'Main': main_sobol,\n    'Total': total_sobol\n})\n\ndisplay(sobol_df)\n\n# Bar plot\nsobol_df.set_index('Element').plot.bar(figsize=(10,5))\nplt.title(\"Sobol sensitivity indices for \u03b3\u2032\")\nplt.ylabel(\"Sobol index\")\nplt.ylim(0, 1)\nplt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Next steps\n\n* **\u03b3\u2032\u2032 modelling**: Repeat Section\u00a05\u20118 with `y = df['\u03b3\u2032\u2032 (mole %)']`.\n* **Better distributions**: Replace uniform priors with empirical or kernel\u2011density estimates.\n* **Interaction visualisations**: Explore pairwise elemental effects using partial\u2011dependence or ALE plots.\n\n---\n*Notebook generated on 2025-08-06.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}